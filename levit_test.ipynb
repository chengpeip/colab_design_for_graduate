{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzLEwDeJk+W9FCHgkLa55n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chengpeip/colab_design_for_graduate/blob/main/levit_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amLwWqgNO81k",
        "outputId": "c7b327bc-aab3-4002-a22a-77b825b428d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import mne\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.signal import stft\n",
        "\n",
        "class EDFPretransform:\n",
        "    def __init__(self, edf_folder, pte_folder, output_img_size=224, nperseg=256, target_sfreq=250):\n",
        "        self.edf_folder = edf_folder\n",
        "        self.pte_folder = pte_folder\n",
        "        self.output_img_size = output_img_size\n",
        "        self.nperseg = nperseg\n",
        "        self.target_sfreq = target_sfreq\n",
        "        self.channel_names = None\n",
        "        self.window_duration = 2  # 时间窗口长度（秒）\n",
        "\n",
        "        # 预编译正则表达式\n",
        "        self.edf_pattern = re.compile(r'^([hs])(\\d+)\\.edf$', re.IGNORECASE)\n",
        "        self.pte_pattern = re.compile(r'^([hs])(\\d+)_pte\\.npy$', re.IGNORECASE)\n",
        "\n",
        "    def _match_files(self):\n",
        "        \"\"\"匹配EDF与对应的PTE窗口文件\"\"\"\n",
        "        edf_files = sorted(\n",
        "            [f for f in os.listdir(self.edf_folder) if self.edf_pattern.match(f)],\n",
        "            key=lambda x: int(self.edf_pattern.match(x).group(2)))\n",
        "\n",
        "        valid_pairs = []\n",
        "        for edf_file in edf_files:\n",
        "            match = self.edf_pattern.match(edf_file)\n",
        "            prefix = match.group(1).lower()\n",
        "            number = match.group(2)\n",
        "\n",
        "            # 构建PTE文件名（约定为相同编号）\n",
        "            pte_file = f\"{prefix}{number}_pte.npy\"\n",
        "            pte_path = os.path.join(self.pte_folder, pte_file)\n",
        "\n",
        "            if os.path.exists(pte_path):\n",
        "                valid_pairs.append((\n",
        "                    os.path.join(self.edf_folder, edf_file),\n",
        "                    pte_path,\n",
        "                    prefix\n",
        "                ))\n",
        "            else:\n",
        "                print(f\"警告: 未找到 {edf_file} 对应的PTE窗口文件 {pte_file}\")\n",
        "\n",
        "        return valid_pairs\n",
        "\n",
        "    def _process_edf(self, edf_path):\n",
        "        \"\"\"处理EDF文件并统一采样率\"\"\"\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(edf_path, preload=True)\n",
        "            if raw.info['sfreq'] != self.target_sfreq:\n",
        "                raw = raw.resample(self.target_sfreq)\n",
        "            return raw\n",
        "        except Exception as e:\n",
        "            print(f\"EDF文件处理失败 {edf_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _segment_data(self, data):\n",
        "        \"\"\"分割数据为时间窗口\"\"\"\n",
        "        window_samples = int(self.window_duration * self.target_sfreq)\n",
        "        n_samples = data.shape[1]\n",
        "        n_windows = n_samples // window_samples\n",
        "\n",
        "        # 截断到整数个窗口\n",
        "        truncated = data[:, :n_windows*window_samples]\n",
        "        return truncated.reshape(data.shape[0], n_windows, window_samples).transpose(1, 0, 2)\n",
        "\n",
        "    def _generate_spectrogram(self, data, sfreq):\n",
        "        \"\"\"生成标准化时频图\"\"\"\n",
        "        f, t, Zxx = stft(data, fs=sfreq, nperseg=self.nperseg)\n",
        "        Zxx = 10 * np.log10(np.abs(Zxx) + 1e-6)\n",
        "        Zxx = (Zxx - Zxx.min()) / (Zxx.max() - Zxx.min() + 1e-6)\n",
        "\n",
        "        from skimage.transform import resize\n",
        "        return resize(Zxx, (self.output_img_size, self.output_img_size),\n",
        "                     mode='reflect', anti_aliasing=True).astype(np.float32)\n",
        "\n",
        "    def process_all_files(self):\n",
        "        \"\"\"主处理流程\"\"\"\n",
        "        file_pairs = self._match_files()\n",
        "\n",
        "        all_images = []\n",
        "        all_pte = []\n",
        "        labels = []\n",
        "\n",
        "        for edf_path, pte_path, prefix in file_pairs:\n",
        "            # 处理EDF文件\n",
        "            raw = self._process_edf(edf_path)\n",
        "            if raw is None:\n",
        "                continue\n",
        "\n",
        "            # 初始化通道信息\n",
        "            if self.channel_names is None:\n",
        "                self.channel_names = raw.ch_names\n",
        "                print(f\"通道配置: {len(self.channel_names)}个通道 ({', '.join(self.channel_names)})\")\n",
        "\n",
        "            # 分割时间窗口\n",
        "            data = raw.get_data()  # [n_channels, n_samples]\n",
        "            data_windows = self._segment_data(data)  # [n_windows, n_channels, window_samples]\n",
        "\n",
        "            # 加载对应的PTE窗口数据\n",
        "            try:\n",
        "                pte_windows = np.load(pte_path)  # 预期形状 [n_windows, 19, 19]\n",
        "                assert pte_windows.ndim == 3, \"PTE数据应为三维数组\"\n",
        "                assert pte_windows.shape[1:] == (len(self.channel_names), len(self.channel_names)), \"PTE维度与通道数不符\"\n",
        "                assert pte_windows.shape[0] == data_windows.shape[0], \"PTE窗口数与数据窗口数不匹配\"\n",
        "            except Exception as e:\n",
        "                print(f\"PTE加载失败 {pte_path}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            # 生成标签（h=0, s=1）\n",
        "            label = 1 if prefix == 's' else 0\n",
        "\n",
        "            # 遍历每个时间窗口\n",
        "            for win_idx in range(data_windows.shape[0]):\n",
        "                # 生成时频图\n",
        "                window_images = []\n",
        "                for ch_idx in range(data_windows.shape[1]):\n",
        "                    ch_data = data_windows[win_idx, ch_idx, :]\n",
        "                    window_images.append(self._generate_spectrogram(ch_data, self.target_sfreq))\n",
        "\n",
        "                # 收集数据\n",
        "                all_images.append(np.stack(window_images))  # [19, H, W]\n",
        "                all_pte.append(pte_windows[win_idx])       # [19, 19]\n",
        "                labels.append(label)\n",
        "\n",
        "        # 转换为张量\n",
        "        images_tensor = torch.FloatTensor(np.array(all_images))  # [N, 19, 224, 224]\n",
        "        pte_tensor = torch.FloatTensor(np.array(all_pte))        # [N, 19, 19]\n",
        "        labels_tensor = torch.LongTensor(labels)                # [N]\n",
        "\n",
        "        # 数据验证\n",
        "        print(f\"\\n处理完成: 总样本数 {len(labels)}\")\n",
        "        print(f\"时频图张量: {images_tensor.shape}\")\n",
        "        print(f\"PTE张量: {pte_tensor.shape}\")\n",
        "        print(f\"标签分布: 健康={labels.count(0)}, 患者={labels.count(1)}\")\n",
        "\n",
        "        return images_tensor, pte_tensor, labels_tensor"
      ],
      "metadata": {
        "collapsed": true,
        "id": "X-XLVSEebRfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edf_processor = EDFPretransform(edf_folder=\"/content\",pte_folder=\"/content\")"
      ],
      "metadata": {
        "id": "AskQpxtXcbfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, pte, labels = edf_processor.process_all_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uowUG8drgEAg",
        "outputId": "acc5b41d-cb66-480d-b737-f6aaebc7bca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/h01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "通道配置: 19个通道 (Fp2, F8, T4, T6, O2, Fp1, F7, T3, T5, O1, F4, C4, P4, F3, C3, P3, Fz, Cz, Pz)\n",
            "Extracting EDF parameters from /content/s01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 211249  =      0.000 ...   844.996 secs...\n",
            "Extracting EDF parameters from /content/s02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 286249  =      0.000 ...  1144.996 secs...\n",
            "Extracting EDF parameters from /content/h02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/h03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/s03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 240999  =      0.000 ...   963.996 secs...\n",
            "Extracting EDF parameters from /content/h04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import timm\n",
        "from timm.data import resolve_model_data_config, create_transform\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "class ChannelProjector(nn.Module):\n",
        "    def __init__(self, in_channels=19, out_channels=3):\n",
        "        super(ChannelProjector, self).__init__()\n",
        "        # 1x1 卷积，将 in_channels 投影到 out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, in_channels, H, W)\n",
        "        return self.conv(x)  # 输出: (batch, out_channels, H, W)\n",
        "\n",
        "# ---------------------------\n",
        "# 2. 定义 EEG Spectrogram 数据集\n",
        "# ---------------------------\n",
        "class EEGSpectrogramDataset(data.Dataset):\n",
        "    def __init__(self, images, pte, labels, model_name=\"levit_128.fb_dist_in1k\", projector=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images: EEG 时频图像数据，形状为 [N, 19, H, W]（19个通道的原始图像）\n",
        "            pte: 对应的 PTE 矩阵数据，形状为 [N, 19, 19]\n",
        "            labels: 样本标签，形状为 [N]\n",
        "            model_name: 用于解析预处理配置的模型名称（例如 LeViT 模型）\n",
        "            projector: 用于将 19 通道转换为 3 通道的模块（如 ChannelProjector 实例）\n",
        "        \"\"\"\n",
        "        # 将输入数据转换为 torch.Tensor（若还不是）\n",
        "        self.images = torch.tensor(images, dtype=torch.float32) if not torch.is_tensor(images) else images\n",
        "        self.pte = torch.tensor(pte, dtype=torch.float32) if not torch.is_tensor(pte) else pte\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long) if not torch.is_tensor(labels) else labels\n",
        "        self.projector = projector\n",
        "\n",
        "        # 获取模型特定的数据预处理配置（包含 input_size, mean, std 等）\n",
        "        self.data_config = resolve_model_data_config(model_name)\n",
        "        # 创建预处理变换\n",
        "        self.transforms = create_transform(**self.data_config, is_training=False)\n",
        "\n",
        "        # 检查数据维度是否匹配预期\n",
        "        assert self.images.ndim == 4, f\"images 期望形状 [N, C, H, W], got {self.images.shape}\"\n",
        "        assert self.pte.ndim == 3, f\"pte 期望形状 [N, C, C], got {self.pte.shape}\"\n",
        "        assert self.labels.ndim == 1, f\"labels 期望形状 [N], got {self.labels.shape}\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 获取 EEG 图像数据，形状为 (19, H, W)\n",
        "        img = self.images[idx]  # Tensor, (19, H, W)\n",
        "        # 如果提供了 projector，将 19 通道转换为 3 通道\n",
        "        if self.projector is not None:\n",
        "            # 添加 batch 维度：变为 (1, 19, H, W)\n",
        "            img = img.unsqueeze(0)\n",
        "            img = self.projector(img)   # 经过 1x1 卷积后变为 (1, 3, H, W)\n",
        "            img = img.squeeze(0)        # 移除 batch 维度，得到 (3, H, W)\n",
        "        # 应用 LeViT 所需的预处理：resize、归一化等\n",
        "        img = self.transforms(img)\n",
        "\n",
        "        # 读取 PTE 矩阵和标签\n",
        "        pte_matrix = self.pte[idx]   # (19, 19)\n",
        "        label = self.labels[idx]\n",
        "        return {'eeg_img': img, 'pte_matrix': pte_matrix, 'label': label}\n",
        "# ---------------------------\n",
        "# 1. 定义 EEG 图像编码器（基于 LeViT）\n",
        "# ---------------------------\n",
        "\n",
        "\n",
        "class EEGImageEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super(EEGImageEncoder, self).__init__()\n",
        "\n",
        "        self.vit = timm.create_model('levit_128.fb_dist_in1k', pretrained=True, num_classes=0)\n",
        "\n",
        "        # 将 ViT 的输出特征投影到目标维度 embed_dim\n",
        "        self.fc = nn.Linear(self.vit.num_features, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.vit(x)\n",
        "        # 投影到指定维度\n",
        "        out = self.fc(features)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 2. 定义 PTE 矩阵编码器（基于全连接网络）\n",
        "# ---------------------------\n",
        "class PTEEncoder(nn.Module):\n",
        "    def __init__(self, num_channels=19, embed_dim=128):\n",
        "        super(PTEEncoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_channels * num_channels, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, num_channels, num_channels)\n",
        "        batch_size = x.size(0)\n",
        "        x = x.view(batch_size, -1)  # 扁平化\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ---------------------------\n",
        "# 3. 定义对比损失（InfoNCE / NT-Xent 损失的简单实现）\n",
        "# ---------------------------\n",
        "def contrastive_loss(z1, z2, temperature=0.07):\n",
        "    # z1, z2: (batch, embed_dim)\n",
        "    z1 = F.normalize(z1, p=2, dim=1)\n",
        "    z2 = F.normalize(z2, p=2, dim=1)\n",
        "    batch_size = z1.size(0)\n",
        "    # 计算相似度矩阵（余弦相似度）\n",
        "    representations = torch.cat([z1, z2], dim=0)  # (2*batch, embed_dim)\n",
        "    similarity_matrix = torch.matmul(representations, representations.T)  # (2*batch, 2*batch)\n",
        "    # 去除自身相似度\n",
        "    mask = torch.eye(2*batch_size, device=z1.device).bool()\n",
        "    similarity_matrix = similarity_matrix.masked_fill(mask, -9e15)\n",
        "    similarity_matrix /= temperature\n",
        "\n",
        "    # 构造标签：同一原始样本的两个增强视角构成正对，标签为 i 与 i+batch_size 对应\n",
        "    labels = torch.arange(batch_size, device=z1.device)\n",
        "    loss_v2p = F.cross_entropy(similarity_matrix[:batch_size, batch_size:], labels)\n",
        "    loss_p2v = F.cross_entropy(similarity_matrix[batch_size:, :batch_size], labels)\n",
        "    return (loss_v2p + loss_p2v) / 2\n",
        "\n",
        "# ---------------------------\n",
        "# 4. 定义分类器\n",
        "# ---------------------------\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=64, num_classes=2):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. 定义跨模态对比学习模型\n",
        "# ---------------------------\n",
        "class CrossModalModel(nn.Module):\n",
        "    def __init__(self, embed_dim=128, num_classes=2):\n",
        "        super(CrossModalModel, self).__init__()\n",
        "        self.eeg_encoder = EEGImageEncoder(embed_dim=embed_dim)\n",
        "        self.pte_encoder = PTEEncoder(num_channels=19, embed_dim=embed_dim)\n",
        "        # 分类器输入为拼接的两个模态特征\n",
        "        self.classifier = Classifier(in_dim=2*embed_dim, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, eeg_img, pte_matrix):\n",
        "        # eeg_img: (batch, 1, H, W)\n",
        "        # pte_matrix: (batch, 19, 19)\n",
        "        f_eeg = self.eeg_encoder(eeg_img)    # (batch, embed_dim)\n",
        "        f_pte = self.pte_encoder(pte_matrix)   # (batch, embed_dim)\n",
        "        fused = torch.cat([f_eeg, f_pte], dim=1)  # (batch, 2*embed_dim)\n",
        "        logits = self.classifier(fused)        # (batch, num_classes)\n",
        "        return f_eeg, f_pte, logits\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zXbNvKaLhs9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 7. 构造数据加载器\n",
        "# ---------------------------\n",
        "batch_size = 4\n",
        "dataset = EEGSpectrogramDataset(images, pte, labels,projector=ChannelProjector())\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# 划分训练集和验证集（80%训练，20%验证）\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "# 创建数据加载器\n",
        "train_loader = data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True  # 加速数据转移到GPU\n",
        ")\n",
        "\n",
        "val_loader = data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # 验证集不需要shuffle\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "RI_BI9Q9Rzrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 修改2：添加验证函数\n",
        "# ---------------------------\n",
        "def validate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            eeg_img = batch['eeg_img'].to(device)\n",
        "            pte_matrix = batch['pte_matrix'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # 前向传播\n",
        "            f_eeg, f_pte, logits = model(eeg_img, pte_matrix)\n",
        "\n",
        "            # 计算损失\n",
        "            loss_cls = criterion_cls(logits, labels)\n",
        "            loss_contrast = contrastive_loss(f_eeg, f_pte)\n",
        "            loss = loss_cls + alpha * loss_contrast\n",
        "\n",
        "            # 统计指标\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            total_correct += (logits.argmax(1) == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100.0 * total_correct / total_samples\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "IOsRngc4Edd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------\n",
        "# 8. 训练流程（含准确率计算）\n",
        "# ---------------------------\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 初始化设备、模型和优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CrossModalModel(embed_dim=128, num_classes=2).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.05)\n",
        "criterion_cls = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl-WeheLGJps",
        "outputId": "12e0b75a-d1b8-46fe-dce6-f784e61c023c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:timm.models._builder:Unexpected keys (head.bn.bias, head.bn.num_batches_tracked, head.bn.running_mean, head.bn.running_var, head.bn.weight, head_dist.bn.bias, head_dist.bn.num_batches_tracked, head_dist.bn.running_mean, head_dist.bn.running_var, head_dist.bn.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------\n",
        "# 修改3：优化训练循环（含早停和学习率调度）\n",
        "# ---------------------------\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# 添加学习率调度器\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',       # 监控验证准确率\n",
        "    factor=0.5,       # 学习率衰减因子\n",
        "    patience=2,       # 等待2个epoch无改进\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 早停参数\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "early_stop_patience = 4  # 连续4次无改进则停止\n",
        "\n",
        "def contrastive_loss(z1, z2, temperature=0.07):\n",
        "    \"\"\"改进的对比损失函数\"\"\"\n",
        "    z1 = F.normalize(z1, p=2, dim=1)\n",
        "    z2 = F.normalize(z2, p=2, dim=1)\n",
        "\n",
        "    # 计算相似度矩阵\n",
        "    sim_matrix = torch.mm(z1, z2.T) / temperature\n",
        "\n",
        "    # 创建标签\n",
        "    labels = torch.arange(z1.size(0), device=z1.device)\n",
        "\n",
        "    # 计算交叉熵损失\n",
        "    loss = F.cross_entropy(sim_matrix, labels)\n",
        "    return loss\n",
        "\n",
        "def calculate_accuracy(logits, labels):\n",
        "    \"\"\"计算分类准确率\"\"\"\n",
        "    _, predicted = torch.max(logits, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    return correct / labels.size(0)\n",
        "\n",
        "\n",
        "\n",
        "# 训练参数\n",
        "num_epochs = 10\n",
        "alpha = 1.0  # 对比损失权重\n",
        "\n",
        "# 训练循环（含准确率计算）\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        # 数据加载（确保与数据集返回格式一致）\n",
        "        eeg_img = batch['eeg_img'].to(device)\n",
        "        pte_matrix = batch['pte_matrix'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # 前向传播\n",
        "        optimizer.zero_grad()\n",
        "        f_eeg, f_pte, logits = model(eeg_img, pte_matrix)\n",
        "\n",
        "        # 损失计算\n",
        "        loss_cls = criterion_cls(logits, labels)\n",
        "        loss_contrast = contrastive_loss(f_eeg, f_pte)\n",
        "        loss = loss_cls + alpha * loss_contrast\n",
        "\n",
        "        # 反向传播\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 统计指标\n",
        "        batch_size = labels.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total_correct += (logits.argmax(1) == labels).sum().item()\n",
        "        total_samples += batch_size\n",
        "\n",
        "        # 实时更新进度条显示\n",
        "        progress_bar.set_postfix({\n",
        "            'lr': optimizer.param_groups[0]['lr'],\n",
        "            'loss': f\"{loss.item():.4f}\",\n",
        "            'acc': f\"{100 * total_correct / total_samples:.1f}%\"\n",
        "        })\n",
        "    # 验证阶段\n",
        "    val_loss, val_acc = validate(model, val_loader, device)\n",
        "\n",
        "    # 学习率调度\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    # 早停机制\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        # 保存最佳模型\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(f\"保存最佳模型，验证准确率: {val_acc:.2f}%\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(f\"\\n早停触发！连续{early_stop_patience}个epoch验证准确率未提升\")\n",
        "            break\n",
        "\n",
        "    train_loss = total_loss / total_samples\n",
        "    train_acc = 100 * total_correct / total_samples\n",
        "    # 打印报告\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"训练损失: {train_loss:.4f} | 训练准确率: {train_acc:.2f}%\")\n",
        "    print(f\"验证损失: {val_loss:.4f} | 验证准确率: {val_acc:.2f}%\")\n",
        "    print(\"─\" * 50)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3cOUy2qR3xU",
        "outputId": "1fd845e8-e260-4fe6-93b5-3323a3a04e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Train Epoch 1: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s, lr=0.0005, loss=0.7394, acc=45.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "保存最佳模型，验证准确率: 66.67%\n",
            "Epoch 1/10\n",
            "训练损失: 0.7064 | 训练准确率: 45.45%\n",
            "验证损失: 0.5616 | 验证准确率: 66.67%\n",
            "──────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 2: 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, lr=0.0005, loss=0.5561, acc=81.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10\n",
            "训练损失: 0.4807 | 训练准确率: 81.82%\n",
            "验证损失: 0.5659 | 验证准确率: 66.67%\n",
            "──────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 3: 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, lr=0.0005, loss=0.3264, acc=86.4%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10\n",
            "训练损失: 0.4570 | 训练准确率: 86.36%\n",
            "验证损失: 0.7676 | 验证准确率: 50.00%\n",
            "──────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 4: 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, lr=0.0005, loss=0.4046, acc=81.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "训练损失: 0.5074 | 训练准确率: 81.82%\n",
            "验证损失: 0.8072 | 验证准确率: 33.33%\n",
            "──────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 5: 100%|██████████| 6/6 [00:03<00:00,  1.74it/s, lr=0.00025, loss=0.0601, acc=95.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "早停触发！连续4个epoch验证准确率未提升\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 修改4：最终测试\n",
        "# ---------------------------\n",
        "# 加载最佳模型\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "\n",
        "# 在完整测试集上评估\n",
        "test_loss, test_acc = validate(model, test_loader, device)\n",
        "print(f\"\\n最终测试结果：损失 {test_loss:.4f} | 准确率 {test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "zWToo9luFrqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}