{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ/JjmY42u9mGGqjH+CA6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chengpeip/colab_design_for_graduate/blob/main/levit_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"1550196419@qq.com\"\n",
        "!git config --global user.name \"chengpeip\"\n"
      ],
      "metadata": {
        "id": "VBNL8r30U7_0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/chengpeip/colab_design_for_graduate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEIYXNZOVFNd",
        "outputId": "e253c2cc-9134-42df-ef46-ffddfb51a4f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'colab_design_for_graduate'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd colab_design_for_graduate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQuHcmJ0VOtd",
        "outputId": "ec0848aa-7369-4042-881b-c72a0fed031b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/colab_design_for_graduate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add levit_test.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_LNIttoVWIN",
        "outputId": "7d7db2ee-b7d4-462f-dfca-d1a8b5438367"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec 'levit_test.ipynb' did not match any files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amLwWqgNO81k",
        "outputId": "aed92ae2-52cc-4ed1-a869-cd5d6796b6b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import mne\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.signal import stft\n",
        "\n",
        "class EDFPretransform:\n",
        "    def __init__(self, edf_folder, pte_folder, output_img_size=224, nperseg=256, target_sfreq=250):\n",
        "        \"\"\"\n",
        "        edf_folder: .edf文件存放路径\n",
        "        pte_folder: PTE矩阵文件存放路径\n",
        "        output_img_size: 输出时频图尺寸\n",
        "        nperseg: STFT窗口长度\n",
        "        target_sfreq: 目标采样率\n",
        "        \"\"\"\n",
        "        self.edf_folder = edf_folder\n",
        "        self.pte_folder = pte_folder\n",
        "        self.output_img_size = output_img_size\n",
        "        self.nperseg = nperseg\n",
        "        self.target_sfreq = target_sfreq\n",
        "        self.channel_names = None\n",
        "\n",
        "        # 预编译正则表达式提高效率\n",
        "        self.edf_pattern = re.compile(r'^([hs])(\\d+)\\.edf$', re.IGNORECASE)\n",
        "        self.pte_pattern = re.compile(r'^([hs])(\\d+)_pte\\.npy$', re.IGNORECASE)\n",
        "\n",
        "    def _match_files(self):\n",
        "        \"\"\"匹配对应的EDF和PTE文件\"\"\"\n",
        "        # 获取并排序所有有效EDF文件\n",
        "        edf_files = sorted(\n",
        "            [f for f in os.listdir(self.edf_folder) if self.edf_pattern.match(f)],\n",
        "            key=lambda x: int(self.edf_pattern.match(x).group(2)))\n",
        "\n",
        "        # 构建文件对\n",
        "        valid_pairs = []\n",
        "        for edf_file in edf_files:\n",
        "            # 提取文件名前缀和编号\n",
        "            match = self.edf_pattern.match(edf_file)\n",
        "            if not match:\n",
        "                continue\n",
        "\n",
        "            prefix = match.group(1).lower()\n",
        "            number = match.group(2)\n",
        "\n",
        "            # 构建对应的PTE文件名\n",
        "            pte_file = f\"{prefix}{number}_pte.npy\"\n",
        "            pte_path = os.path.join(self.pte_folder, pte_file)\n",
        "\n",
        "            if os.path.exists(pte_path):\n",
        "                valid_pairs.append((\n",
        "                    os.path.join(self.edf_folder, edf_file),\n",
        "                    pte_path,\n",
        "                    prefix  # 用于生成标签\n",
        "                ))\n",
        "            else:\n",
        "                print(f\"警告: 未找到 {edf_file} 对应的PTE文件 {pte_file}\")\n",
        "\n",
        "        return valid_pairs\n",
        "\n",
        "    def _process_edf(self, edf_path):\n",
        "        \"\"\"处理单个EDF文件\"\"\"\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(edf_path, preload=True)\n",
        "            raw = self._resample_data(raw)\n",
        "            return raw\n",
        "        except Exception as e:\n",
        "            print(f\"无法读取文件 {edf_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _resample_data(self, raw):\n",
        "        \"\"\"统一采样率\"\"\"\n",
        "        if raw.info['sfreq'] != self.target_sfreq:\n",
        "            raw = raw.resample(self.target_sfreq)\n",
        "        return raw\n",
        "\n",
        "    def _generate_spectrogram(self, data, sfreq):\n",
        "        \"\"\"生成时频图\"\"\"\n",
        "        f, t, Zxx = stft(data, fs=sfreq, nperseg=self.nperseg)\n",
        "        Zxx = np.abs(Zxx)\n",
        "\n",
        "        # 转换为dB标度并归一化\n",
        "        Zxx = 10 * np.log10(Zxx + 1e-6)\n",
        "        Zxx = (Zxx - Zxx.min()) / (Zxx.max() - Zxx.min() + 1e-6)\n",
        "\n",
        "        # 调整尺寸\n",
        "        from skimage.transform import resize\n",
        "        img = resize(Zxx, (self.output_img_size, self.output_img_size),\n",
        "                    mode='reflect', anti_aliasing=True)\n",
        "        return img.astype(np.float32)\n",
        "\n",
        "    def process_all_files(self):\n",
        "        \"\"\"处理所有有效文件对\"\"\"\n",
        "        file_pairs = self._match_files()\n",
        "\n",
        "        all_images = []\n",
        "        all_pte = []\n",
        "        labels = []\n",
        "\n",
        "        for edf_path, pte_path, prefix in file_pairs:\n",
        "\n",
        "            # 处理EDF文件\n",
        "            raw = self._process_edf(edf_path)\n",
        "            if raw is None:\n",
        "                continue\n",
        "\n",
        "            # 记录通道信息\n",
        "            if self.channel_names is None:\n",
        "                self.channel_names = raw.ch_names\n",
        "                print(f\"检测到{len(self.channel_names)}个通道: {self.channel_names}\")\n",
        "\n",
        "            # 生成标签（h=0, s=1）\n",
        "            label = 1 if prefix == 's' else 0\n",
        "            labels.append(label)\n",
        "\n",
        "            # 生成时频图\n",
        "            sample_images = []\n",
        "            for ch_idx in range(len(self.channel_names)):\n",
        "                ch_data = raw.get_data(picks=ch_idx).flatten()\n",
        "                img = self._generate_spectrogram(ch_data, self.target_sfreq)\n",
        "                sample_images.append(img)\n",
        "\n",
        "            # 加载PTE矩阵\n",
        "            try:\n",
        "                pte_matrix = np.load(pte_path)\n",
        "                assert pte_matrix.shape == (len(self.channel_names), len(self.channel_names))\n",
        "                all_pte.append(pte_matrix)\n",
        "            except Exception as e:\n",
        "                print(f\"加载PTE文件失败: {pte_path} - {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            all_images.append(np.stack(sample_images))\n",
        "\n",
        "        # 转换为张量\n",
        "        images_tensor = torch.FloatTensor(np.array(all_images))  # [N, C, H, W]\n",
        "        pte_tensor = torch.FloatTensor(np.array(all_pte))        # [N, C, C]\n",
        "        labels_tensor = torch.LongTensor(labels)                # [N]\n",
        "\n",
        "        # 数据验证\n",
        "        print(\"\\n数据处理完成:\")\n",
        "        print(f\"图像张量形状: {images_tensor.shape}\")\n",
        "        print(f\"PTE张量形状: {pte_tensor.shape}\")\n",
        "        print(labels)\n",
        "\n",
        "        return images_tensor, pte_tensor, labels_tensor"
      ],
      "metadata": {
        "collapsed": true,
        "id": "X-XLVSEebRfS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edf_processor = EDFPretransform(edf_folder=\"/content\",pte_folder=\"/content\")"
      ],
      "metadata": {
        "id": "AskQpxtXcbfR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, pte, labels = edf_processor.process_all_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uowUG8drgEAg",
        "outputId": "e5666440-8eb9-4dbb-def2-b7e693f778f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/s01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 211249  =      0.000 ...   844.996 secs...\n",
            "检测到19个通道: ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4', 'C4', 'P4', 'F3', 'C3', 'P3', 'Fz', 'Cz', 'Pz']\n",
            "Extracting EDF parameters from /content/h01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "Extracting EDF parameters from /content/s02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 286249  =      0.000 ...  1144.996 secs...\n",
            "Extracting EDF parameters from /content/h02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/h03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/s03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 240999  =      0.000 ...   963.996 secs...\n",
            "Extracting EDF parameters from /content/s04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 301249  =      0.000 ...  1204.996 secs...\n",
            "Extracting EDF parameters from /content/h04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "Extracting EDF parameters from /content/s05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 222499  =      0.000 ...   889.996 secs...\n",
            "Extracting EDF parameters from /content/h05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 236249  =      0.000 ...   944.996 secs...\n",
            "Extracting EDF parameters from /content/s06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 184999  =      0.000 ...   739.996 secs...\n",
            "Extracting EDF parameters from /content/h06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 232499  =      0.000 ...   929.996 secs...\n",
            "Extracting EDF parameters from /content/s07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 336499  =      0.000 ...  1345.996 secs...\n",
            "Extracting EDF parameters from /content/h07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/h08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/s08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227749  =      0.000 ...   910.996 secs...\n",
            "Extracting EDF parameters from /content/s09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 296249  =      0.000 ...  1184.996 secs...\n",
            "Extracting EDF parameters from /content/h09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 226249  =      0.000 ...   904.996 secs...\n",
            "Extracting EDF parameters from /content/h10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 278749  =      0.000 ...  1114.996 secs...\n",
            "Extracting EDF parameters from /content/s10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 212499  =      0.000 ...   849.996 secs...\n",
            "Extracting EDF parameters from /content/s11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 339999  =      0.000 ...  1359.996 secs...\n",
            "Extracting EDF parameters from /content/h11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 228749  =      0.000 ...   914.996 secs...\n",
            "Extracting EDF parameters from /content/s12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 271749  =      0.000 ...  1086.996 secs...\n",
            "Extracting EDF parameters from /content/h12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 224999  =      0.000 ...   899.996 secs...\n",
            "Extracting EDF parameters from /content/s13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 283749  =      0.000 ...  1134.996 secs...\n",
            "Extracting EDF parameters from /content/h13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 241249  =      0.000 ...   964.996 secs...\n",
            "Extracting EDF parameters from /content/s14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 542499  =      0.000 ...  2169.996 secs...\n",
            "Extracting EDF parameters from /content/h14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 216249  =      0.000 ...   864.996 secs...\n",
            "\n",
            "数据处理完成:\n",
            "图像张量形状: torch.Size([28, 19, 224, 224])\n",
            "PTE张量形状: torch.Size([28, 19, 19])\n",
            "[1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import timm\n",
        "from timm.data import resolve_model_data_config, create_transform\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "class ChannelProjector(nn.Module):\n",
        "    def __init__(self, in_channels=19, out_channels=3):\n",
        "        super(ChannelProjector, self).__init__()\n",
        "        # 1x1 卷积，将 in_channels 投影到 out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, in_channels, H, W)\n",
        "        return self.conv(x)  # 输出: (batch, out_channels, H, W)\n",
        "\n",
        "# ---------------------------\n",
        "# 2. 定义 EEG Spectrogram 数据集\n",
        "# ---------------------------\n",
        "class EEGSpectrogramDataset(data.Dataset):\n",
        "    def __init__(self, images, pte, labels, model_name=\"levit_128.fb_dist_in1k\", projector=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images: EEG 时频图像数据，形状为 [N, 19, H, W]（19个通道的原始图像）\n",
        "            pte: 对应的 PTE 矩阵数据，形状为 [N, 19, 19]\n",
        "            labels: 样本标签，形状为 [N]\n",
        "            model_name: 用于解析预处理配置的模型名称（例如 LeViT 模型）\n",
        "            projector: 用于将 19 通道转换为 3 通道的模块（如 ChannelProjector 实例）\n",
        "        \"\"\"\n",
        "        # 将输入数据转换为 torch.Tensor（若还不是）\n",
        "        self.images = torch.tensor(images, dtype=torch.float32) if not torch.is_tensor(images) else images\n",
        "        self.pte = torch.tensor(pte, dtype=torch.float32) if not torch.is_tensor(pte) else pte\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long) if not torch.is_tensor(labels) else labels\n",
        "        self.projector = projector\n",
        "\n",
        "        # 获取模型特定的数据预处理配置（包含 input_size, mean, std 等）\n",
        "        self.data_config = resolve_model_data_config(model_name)\n",
        "        # 创建预处理变换\n",
        "        self.transforms = create_transform(**self.data_config, is_training=False)\n",
        "\n",
        "        # 检查数据维度是否匹配预期\n",
        "        assert self.images.ndim == 4, f\"images 期望形状 [N, C, H, W], got {self.images.shape}\"\n",
        "        assert self.pte.ndim == 3, f\"pte 期望形状 [N, C, C], got {self.pte.shape}\"\n",
        "        assert self.labels.ndim == 1, f\"labels 期望形状 [N], got {self.labels.shape}\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 获取 EEG 图像数据，形状为 (19, H, W)\n",
        "        img = self.images[idx]  # Tensor, (19, H, W)\n",
        "        # 如果提供了 projector，将 19 通道转换为 3 通道\n",
        "        if self.projector is not None:\n",
        "            # 添加 batch 维度：变为 (1, 19, H, W)\n",
        "            img = img.unsqueeze(0)\n",
        "            img = self.projector(img)   # 经过 1x1 卷积后变为 (1, 3, H, W)\n",
        "            img = img.squeeze(0)        # 移除 batch 维度，得到 (3, H, W)\n",
        "        # 应用 LeViT 所需的预处理：resize、归一化等\n",
        "        img = self.transforms(img)\n",
        "\n",
        "        # 读取 PTE 矩阵和标签\n",
        "        pte_matrix = self.pte[idx]   # (19, 19)\n",
        "        label = self.labels[idx]\n",
        "        return {'eeg_img': img, 'pte_matrix': pte_matrix, 'label': label}\n",
        "# ---------------------------\n",
        "# 1. 定义 EEG 图像编码器（基于 LeViT）\n",
        "# ---------------------------\n",
        "\n",
        "\n",
        "class EEGImageEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super(EEGImageEncoder, self).__init__()\n",
        "\n",
        "        self.vit = timm.create_model('levit_128.fb_dist_in1k', pretrained=True, num_classes=0)\n",
        "\n",
        "        # 将 ViT 的输出特征投影到目标维度 embed_dim\n",
        "        self.fc = nn.Linear(self.vit.num_features, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.vit(x)\n",
        "        # 投影到指定维度\n",
        "        out = self.fc(features)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 2. 定义 PTE 矩阵编码器（基于全连接网络）\n",
        "# ---------------------------\n",
        "class PTEEncoder(nn.Module):\n",
        "    def __init__(self, num_channels=19, embed_dim=128):\n",
        "        super(PTEEncoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_channels * num_channels, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, num_channels, num_channels)\n",
        "        batch_size = x.size(0)\n",
        "        x = x.view(batch_size, -1)  # 扁平化\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ---------------------------\n",
        "# 3. 定义对比损失（InfoNCE / NT-Xent 损失的简单实现）\n",
        "# ---------------------------\n",
        "def contrastive_loss(z1, z2, temperature=0.07):\n",
        "    # z1, z2: (batch, embed_dim)\n",
        "    z1 = F.normalize(z1, p=2, dim=1)\n",
        "    z2 = F.normalize(z2, p=2, dim=1)\n",
        "    batch_size = z1.size(0)\n",
        "    # 计算相似度矩阵（余弦相似度）\n",
        "    representations = torch.cat([z1, z2], dim=0)  # (2*batch, embed_dim)\n",
        "    similarity_matrix = torch.matmul(representations, representations.T)  # (2*batch, 2*batch)\n",
        "    # 去除自身相似度\n",
        "    mask = torch.eye(2*batch_size, device=z1.device).bool()\n",
        "    similarity_matrix = similarity_matrix.masked_fill(mask, -9e15)\n",
        "    similarity_matrix /= temperature\n",
        "\n",
        "    # 构造标签：同一原始样本的两个增强视角构成正对，标签为 i 与 i+batch_size 对应\n",
        "    labels = torch.arange(batch_size, device=z1.device)\n",
        "    loss_v2p = F.cross_entropy(similarity_matrix[:batch_size, batch_size:], labels)\n",
        "    loss_p2v = F.cross_entropy(similarity_matrix[batch_size:, :batch_size], labels)\n",
        "    return (loss_v2p + loss_p2v) / 2\n",
        "\n",
        "# ---------------------------\n",
        "# 4. 定义分类器\n",
        "# ---------------------------\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=64, num_classes=2):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. 定义跨模态对比学习模型\n",
        "# ---------------------------\n",
        "class CrossModalModel(nn.Module):\n",
        "    def __init__(self, embed_dim=128, num_classes=2):\n",
        "        super(CrossModalModel, self).__init__()\n",
        "        self.eeg_encoder = EEGImageEncoder(embed_dim=embed_dim)\n",
        "        self.pte_encoder = PTEEncoder(num_channels=19, embed_dim=embed_dim)\n",
        "        # 分类器输入为拼接的两个模态特征\n",
        "        self.classifier = Classifier(in_dim=2*embed_dim, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, eeg_img, pte_matrix):\n",
        "        # eeg_img: (batch, 1, H, W)\n",
        "        # pte_matrix: (batch, 19, 19)\n",
        "        f_eeg = self.eeg_encoder(eeg_img)    # (batch, embed_dim)\n",
        "        f_pte = self.pte_encoder(pte_matrix)   # (batch, embed_dim)\n",
        "        fused = torch.cat([f_eeg, f_pte], dim=1)  # (batch, 2*embed_dim)\n",
        "        logits = self.classifier(fused)        # (batch, num_classes)\n",
        "        return f_eeg, f_pte, logits\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zXbNvKaLhs9T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 7. 构造数据加载器\n",
        "# ---------------------------\n",
        "batch_size = 4\n",
        "dataset = EEGSpectrogramDataset(images, pte, labels,projector=ChannelProjector())\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# 划分训练集和验证集（80%训练，20%验证）\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "# 创建数据加载器\n",
        "train_loader = data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True  # 加速数据转移到GPU\n",
        ")\n",
        "\n",
        "val_loader = data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # 验证集不需要shuffle\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "RI_BI9Q9Rzrm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 修改2：添加验证函数\n",
        "# ---------------------------\n",
        "def validate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            eeg_img = batch['eeg_img'].to(device)\n",
        "            pte_matrix = batch['pte_matrix'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # 前向传播\n",
        "            f_eeg, f_pte, logits = model(eeg_img, pte_matrix)\n",
        "\n",
        "            # 计算损失\n",
        "            loss_cls = criterion_cls(logits, labels)\n",
        "            loss_contrast = contrastive_loss(f_eeg, f_pte)\n",
        "            loss = loss_cls + alpha * loss_contrast\n",
        "\n",
        "            # 统计指标\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            total_correct += (logits.argmax(1) == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100.0 * total_correct / total_samples\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "IOsRngc4Edd9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------\n",
        "# 8. 训练流程（含准确率计算）\n",
        "# ---------------------------\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 初始化设备、模型和优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CrossModalModel(embed_dim=128, num_classes=2).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.05)\n",
        "criterion_cls = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl-WeheLGJps",
        "outputId": "12e0b75a-d1b8-46fe-dce6-f784e61c023c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:timm.models._builder:Unexpected keys (head.bn.bias, head.bn.num_batches_tracked, head.bn.running_mean, head.bn.running_var, head.bn.weight, head_dist.bn.bias, head_dist.bn.num_batches_tracked, head_dist.bn.running_mean, head_dist.bn.running_var, head_dist.bn.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------\n",
        "# 修改3：优化训练循环（含早停和学习率调度）\n",
        "# ---------------------------\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# 添加学习率调度器\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',       # 监控验证准确率\n",
        "    factor=0.5,       # 学习率衰减因子\n",
        "    patience=2,       # 等待2个epoch无改进\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 早停参数\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "early_stop_patience = 4  # 连续4次无改进则停止\n",
        "\n",
        "def contrastive_loss(z1, z2, temperature=0.07):\n",
        "    \"\"\"改进的对比损失函数\"\"\"\n",
        "    z1 = F.normalize(z1, p=2, dim=1)\n",
        "    z2 = F.normalize(z2, p=2, dim=1)\n",
        "\n",
        "    # 计算相似度矩阵\n",
        "    sim_matrix = torch.mm(z1, z2.T) / temperature\n",
        "\n",
        "    # 创建标签\n",
        "    labels = torch.arange(z1.size(0), device=z1.device)\n",
        "\n",
        "    # 计算交叉熵损失\n",
        "    loss = F.cross_entropy(sim_matrix, labels)\n",
        "    return loss\n",
        "\n",
        "def calculate_accuracy(logits, labels):\n",
        "    \"\"\"计算分类准确率\"\"\"\n",
        "    _, predicted = torch.max(logits, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    return correct / labels.size(0)\n",
        "\n",
        "\n",
        "\n",
        "# 训练参数\n",
        "num_epochs = 10\n",
        "alpha = 1.0  # 对比损失权重\n",
        "\n",
        "# 训练循环（含准确率计算）\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        # 数据加载（确保与数据集返回格式一致）\n",
        "        eeg_img = batch['eeg_img'].to(device)\n",
        "        pte_matrix = batch['pte_matrix'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # 前向传播\n",
        "        optimizer.zero_grad()\n",
        "        f_eeg, f_pte, logits = model(eeg_img, pte_matrix)\n",
        "\n",
        "        # 损失计算\n",
        "        loss_cls = criterion_cls(logits, labels)\n",
        "        loss_contrast = contrastive_loss(f_eeg, f_pte)\n",
        "        loss = loss_cls + alpha * loss_contrast\n",
        "\n",
        "        # 反向传播\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 统计指标\n",
        "        batch_size = labels.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total_correct += (logits.argmax(1) == labels).sum().item()\n",
        "        total_samples += batch_size\n",
        "\n",
        "        # 实时更新进度条显示\n",
        "        progress_bar.set_postfix({\n",
        "            'lr': optimizer.param_groups[0]['lr'],\n",
        "            'loss': f\"{loss.item():.4f}\",\n",
        "            'acc': f\"{100 * total_correct / total_samples:.1f}%\"\n",
        "        })\n",
        "    # 验证阶段\n",
        "    val_loss, val_acc = validate(model, val_loader, device)\n",
        "\n",
        "    # 学习率调度\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    # 早停机制\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        # 保存最佳模型\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(f\"保存最佳模型，验证准确率: {val_acc:.2f}%\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(f\"\\n早停触发！连续{early_stop_patience}个epoch验证准确率未提升\")\n",
        "            break\n",
        "\n",
        "    train_loss = total_loss / total_samples\n",
        "    train_acc = 100 * total_correct / total_samples\n",
        "    # 打印报告\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"训练损失: {train_loss:.4f} | 训练准确率: {train_acc:.2f}%\")\n",
        "    print(f\"验证损失: {val_loss:.4f} | 验证准确率: {val_acc:.2f}%\")\n",
        "    print(\"─\" * 50)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3cOUy2qR3xU",
        "outputId": "1fd845e8-e260-4fe6-93b5-3323a3a04e47"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Train Epoch 1: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s, lr=0.0005, loss=0.7394, acc=45.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "保存最佳模型，验证准确率: 66.67%\n",
            "Epoch 1/10\n",
            "训练损失: 0.7064 | 训练准确率: 45.45%\n",
            "验证损失: 0.5616 | 验证准确率: 66.67%\n",
            "──────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 2: 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, lr=0.0005, loss=0.5561, acc=81.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10\n",
            "训练损失: 0.4807 | 训练准确率: 81.82%\n",
            "验证损失: 0.5659 | 验证准确率: 66.67%\n",
            "──────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 3: 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, lr=0.0005, loss=0.3264, acc=86.4%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10\n",
            "训练损失: 0.4570 | 训练准确率: 86.36%\n",
            "验证损失: 0.7676 | 验证准确率: 50.00%\n",
            "──────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 4: 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, lr=0.0005, loss=0.4046, acc=81.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "训练损失: 0.5074 | 训练准确率: 81.82%\n",
            "验证损失: 0.8072 | 验证准确率: 33.33%\n",
            "──────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 5: 100%|██████████| 6/6 [00:03<00:00,  1.74it/s, lr=0.00025, loss=0.0601, acc=95.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "早停触发！连续4个epoch验证准确率未提升\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 修改4：最终测试\n",
        "# ---------------------------\n",
        "# 加载最佳模型\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "\n",
        "# 在完整测试集上评估\n",
        "test_loss, test_acc = validate(model, test_loader, device)\n",
        "print(f\"\\n最终测试结果：损失 {test_loss:.4f} | 准确率 {test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "zWToo9luFrqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}